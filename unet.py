# -*- coding: utf-8 -*-
"""notebookc6488a08cb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jMPW1X4ivnAcXjbAueQs1jsM2WUXvkC7
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
# data processing, CSV file I/O (e.g. pd.read_csv)
import cv2
import tensorflow as tf



print("Num GPUs Available: ", (tf.config.experimental.list_physical_devices('GPU')))

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
import matplotlib.pyplot as plt

# TrainImg = []
# TrainMask = []
# TestImg = []
# TestMask = []

# for dirname, _, filenames in os.walk('/kaggle/input'):
#     d = dirname.split('/')
#     d1 = d[-2]
#     d2 = d[-1]
#     #count=0
#     if d1=='train':
#         if d2=='images':
#             for i in filenames:
#                 img = plt.imread(dirname+'/'+i)
#                 TrainImg.append(img)

#         if d2=='masks':
#             for i in filenames:
#                 img = plt.imread(dirname+'/'+i)
#                 TrainMask.append(img)

#     if d1=='test':
#         if d2=='images':
#             for i in filenames:
#                 img = plt.imread(dirname+'/'+i)
#                 TestImg.append(img)
#             #print(f"Test image : {filenames}")
#         if d2=='masks':
#             for i in filenames:
#                 img = plt.imread(dirname+'/'+i)
#                 TestMask.append(img)
#             #print(f"Test mask : {filenames}")

def load_and_preprocess_data(image_path):
    # Read and decode image using OpenCV
    image = cv2.imread(image_path, cv2.IMREAD_COLOR)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB format
     # Resize the image to your desired dimensions
    image=cv2.resize(image,(128,128))
    # Normalize image to [0, 1] if needed
    image = image / 255.0

    return image




import numpy as np

def load_and_preprocess_mask(image_path):
    # Convert BGR image to RGB
    image = cv2.imread(image_path, cv2.IMREAD_COLOR)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image_rgb =cv2.resize(image_rgb ,(128,128))
    image_gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)
    one_hot_mask = tf.keras.utils.to_categorical( image_gray/255.0, num_classes=2)


    return one_hot_mask 




# Define data paths
train_data_dir = '/home/arnav/Downloads/cracksegmentation/crack_segmentation_dataset/train/images'  # Replace with the path to your training data directory
train_mask_dir = '/home/arnav/Downloads/cracksegmentation/crack_segmentation_dataset/train/masks'  # Replace with the path to your training masks directory



train_data_paths=os.listdir(train_data_dir)[:3000]
train_mask_paths=os.listdir(train_mask_dir)[:3000]
train_data_paths.sort()
train_mask_paths.sort()


# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

# TrainImg = np.array(TrainImg)
# TestImg = np.array(TestImg)
# TestMask = np.array(TestMask)
# TrainMask = np.array(TrainMask)

# TrainMask.shape
TrainImg=[load_and_preprocess_data('/home/arnav/Downloads/cracksegmentation/crack_segmentation_dataset/train/images/'+image_path) for image_path in train_data_paths]
TrainMask =[load_and_preprocess_mask("/home/arnav/Downloads/cracksegmentation/crack_segmentation_dataset/train/masks/"+image_path) for image_path in train_mask_paths]
from sklearn.model_selection import train_test_split
TrainImg, X_Val , TrainMask, Y_Val = train_test_split(TrainImg, TrainMask , test_size=0.2, shuffle=True)

# Define data paths for validation
val_data_dir = '/home/arnav/Downloads/cracksegmentation/crack_segmentation_dataset/test/images'  # Replace with the path to your validation data directory
val_mask_dir = '/home/arnav/Downloads/cracksegmentation/crack_segmentation_dataset/test/masks'  # Replace with the path to your validation masks directory

val_data_paths=os.listdir(val_data_dir)[:400]
val_mask_paths=os.listdir(val_mask_dir)[:400]



# Ensure the order of validation image and mask file paths matches
val_data_paths.sort()
val_mask_paths.sort()


val_img=[load_and_preprocess_data('/home/arnav/Downloads/cracksegmentation/crack_segmentation_dataset/test/images/'+image_path) for image_path in val_data_paths]
val_mask=[load_and_preprocess_mask('/home/arnav/Downloads/cracksegmentation/crack_segmentation_dataset/test/images/'+image_path) for image_path in val_mask_paths]

TestImg =np.array(val_img)
TestMask =np.array(val_mask)
X_Val=np.array(X_Val)
Y_Val=np.array(Y_Val)


# from sklearn.model_selection import train_test_split
# X_Train, X_Val, Y_Train, Y_Val = train_test_split(X, Y , test_size=0.2, stratify=Y)

TrainImg=np.array(TrainImg)
TrainMask=np.array(TrainMask)

print("Shape of TrainImg:", TrainImg.shape)
print("Shape of TrainMask:", TrainMask.shape)
print("Shape of TestImg:", TestImg.shape)
print("Shape of TestMask:", TestMask.shape)

print("Shape of ValImg:", X_Val.shape)
print("Shape of ValMask:",Y_Val.shape)


def conv(input_tensor, n_filters, kernel_size = 3):

    x = input_tensor
    for i in range(2):
        x = tf.keras.layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size), kernel_initializer = 'he_normal', padding = 'same')(x)
        x = tf.keras.layers.Activation('relu')(x)
    return x

def encoder_block(inputs, n_filters=64, pool_size=(2,2), dropout=0.3):
    f = conv(inputs, n_filters=n_filters)
    p = tf.keras.layers.MaxPooling2D(pool_size=pool_size)(f)
    p = tf.keras.layers.Dropout(0.3)(p)
    return f, p

def encoder(inputs):
    f1, p1 = encoder_block(inputs, n_filters=64, pool_size=(2,2), dropout=0.3)
    #f2, p2 = encoder_block(p1, n_filters=128, pool_size=(2,2), dropout=0.3)
    #f3, p3 = encoder_block(p2, n_filters=256, pool_size=(2,2), dropout=0.3)
    #f4, p4 = encoder_block(p3, n_filters=512, pool_size=(2,2), dropout=0.3)
    return p1, f1#, f2, f3, f4)

def bottleneck(inputs):
    bottle_neck = conv(inputs, n_filters=1024)
    return bottle_neck

def decoder_block(inputs, conv_output, n_filters=64, kernel_size=3, strides=3, dropout=0.3):
    u = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size, strides = strides, padding = 'same')(inputs)
    c = tf.keras.layers.concatenate([u, conv_output])
    c = tf.keras.layers.Dropout(dropout)(c)
    c = conv(c, n_filters, kernel_size=3)
    return c

def decoder(inputs, convs, output_channels):
    f1 = convs#, f2, f3, f4 = convs
    c6 = decoder_block(inputs, f1, n_filters=64, kernel_size=(3,3), strides=(2,2), dropout=0.3)
    #c7 = decoder_block(c6, f3, n_filters=256, kernel_size=(3,3), strides=(2,2), dropout=0.3)
    #c8 = decoder_block(c7, f2, n_filters=128, kernel_size=(3,3), strides=(2,2), dropout=0.3)
    #c9 = decoder_block(c8, f1, n_filters=64, kernel_size=(3,3), strides=(2,2), dropout=0.3)
    outputs = tf.keras.layers.Conv2D(output_channels, (1, 1), activation='sigmoid')(c6)
    return outputs

OUTPUT_CHANNELS = 2

def unet():
    # specify the input shape
    inputs = tf.keras.layers.Input(shape=(128, 128, 3))
    # feed the inputs to the encoder
    encoder_output, convs = encoder(inputs)
    # feed the encoder output to the bottleneck
    bottle_neck = bottleneck(encoder_output)
    # feed the bottleneck and encoder block outputs to the decoder
    # specify the number of classes via the `output_channels` argument
    outputs = decoder(bottle_neck, convs, output_channels=OUTPUT_CHANNELS)
    # create the model
    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model


with tf.device('/GPU:0'):
    model = unet()
    model.summary()
    model.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])
    model_history = model.fit(TrainImg,TrainMask, epochs=100, batch_size=20, validation_split=False, validation_data=(X_Val,Y_Val), verbose=2,shuffle=True)

acc = model.evaluate(TestImg,TestMask)

model.save("unetModel.h5")
plt.plot(model_history.history["loss"])
plt.title("Training Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.show()
print(acc)